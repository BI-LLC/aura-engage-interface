# AURA Voice AI ğŸ¯

An intelligent, multi-tenant voice AI assistant that combines cutting-edge LLMs (Grok & GPT-4), ultra-realistic voice synthesis (ElevenLabs), and personalized memory for natural, real-time conversations. Built with modern architecture using FastAPI, React TypeScript, and Supabase for enterprise-grade scalability and security.

## ğŸŒŸ Features

### ğŸ§  **Intelligent AI Capabilities**
- **Smart LLM Routing**: Intelligently routes between Grok-4 and GPT-4-turbo based on query complexity and type
- **Real-time Streaming**: Token-by-token response generation for natural conversation flow
- **Context Awareness**: Maintains conversation history and user preferences across sessions
- **Multi-modal Support**: Seamless integration of voice, text, and function calling

### ğŸ¤ **Advanced Voice Technology**
- **Ultra-realistic Voice Synthesis**: High-quality text-to-speech using ElevenLabs
- **Real-time Speech Recognition**: Accurate speech-to-text with OpenAI Whisper
- **Voice Activity Detection**: Smart detection of speech start/end with WebRTC VAD
- **Continuous Conversation**: Natural back-and-forth dialogue without push-to-talk
- **Interruption Handling**: Users can naturally interrupt AI responses

### ğŸ¢ **Enterprise Features**
- **Multi-tenant Architecture**: Complete data isolation for multiple organizations
- **Scalable Infrastructure**: Built for high-volume, concurrent voice sessions
- **GDPR Compliant**: Full data export, deletion, and privacy controls
- **Admin Dashboard**: Comprehensive management interface for system administration
- **Document Processing**: AI-powered document ingestion and knowledge extraction
- **Real-time Analytics**: Usage tracking and performance monitoring

### ğŸš€ **Modern Technology Stack**
- **Backend**: FastAPI with async/await for high performance
- **Frontend**: React TypeScript with modern UI components
- **Database**: Supabase with real-time subscriptions and RLS
- **Voice Pipeline**: WebSocket-based real-time audio streaming
- **Deployment**: Docker-ready with multi-environment support

## ğŸš€ Quick Start

### ğŸš¨ **IMPORTANT: Before You Start**
Make sure you have these API keys ready:
- **xAI API Key** (for Grok AI) - [Get it here](https://x.ai/)
- **OpenAI API Key** (for GPT-4 & Whisper) - [Get it here](https://platform.openai.com/)
- **ElevenLabs API Key** (for voice synthesis) - [Get it here](https://elevenlabs.io/)

**Without these keys, the AI will not work!**

### Prerequisites

- Python 3.12+
- Node.js 18+ and npm
- Redis (optional, will use in-memory fallback)
- API Keys for:
  - Grok (xAI)
  - OpenAI (GPT-4-turbo & Whisper)
  - ElevenLabs (Text-to-speech)

### Installation

1. **Clone the repository with submodules**
```bash
git clone --recurse-submodules https://github.com/yourusername/aura-voice-ai.git
cd aura-voice-ai
```

**âš ï¸ IMPORTANT: If you already cloned without submodules, run:**
```bash
git submodule update --init --recursive
```

2. **Set up backend environment variables**
```bash
cd backend
cp env.example .env
# Edit .env with your API keys
```

**âš ï¸ CRITICAL: You MUST add your own API keys to make the AI work!**
- **GROK_API_KEY**: Get from [xAI](https://x.ai/) (for Grok AI)
- **OPENAI_API_KEY**: Get from [OpenAI](https://platform.openai.com/) (for GPT-4 and Whisper)
- **ELEVENLABS_API_KEY**: Get from [ElevenLabs](https://elevenlabs.io/) (for voice synthesis)

Without these API keys, the voice AI will not respond to any requests!

3. **Install backend dependencies**
```bash
pip install -r requirements.txt
```

4. **Set up frontend**
```bash
cd ../frontend/aura-react-frontend
npm install
```

5. **Start the backend server**
```bash
cd ../../backend
python -m app.main
# Server runs on http://localhost:8000
```

6. **Start the frontend development server**
```bash
cd ../frontend/aura-react-frontend
npm run dev
# Frontend runs on http://localhost:5173
```

7. **Test the system**
```bash
# Backend test interface:
http://localhost:8000/test

# Frontend application:
http://localhost:5173
```

## ğŸ“ Project Structure

```
aura-voice-ai/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py                    # FastAPI application
â”‚   â”‚   â”œâ”€â”€ config.py                  # Configuration
â”‚   â”‚   â”œâ”€â”€ routers/                   # API endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py               # Chat endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ voice.py              # Voice processing
â”‚   â”‚   â”‚   â”œâ”€â”€ continuous_voice.py   # Real-time voice processing
â”‚   â”‚   â”‚   â”œâ”€â”€ streaming.py          # Streaming endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ documents.py          # Document processing
â”‚   â”‚   â”‚   â”œâ”€â”€ memory.py             # Memory management
â”‚   â”‚   â”‚   â”œâ”€â”€ admin.py              # Admin dashboard
â”‚   â”‚   â”‚   â””â”€â”€ tenant_admin.py       # Tenant management
â”‚   â”‚   â”œâ”€â”€ services/                  # Core services
â”‚   â”‚   â”‚   â”œâ”€â”€ smart_router.py       # LLM routing (OpenAI/Grok)
â”‚   â”‚   â”‚   â”œâ”€â”€ memory_engine.py      # User memory
â”‚   â”‚   â”‚   â”œâ”€â”€ voice_pipeline.py     # STT/TTS pipeline
â”‚   â”‚   â”‚   â”œâ”€â”€ streaming_handler.py  # Audio streaming
â”‚   â”‚   â”‚   â”œâ”€â”€ persona_manager.py    # Personalization
â”‚   â”‚   â”‚   â”œâ”€â”€ tenant_manager.py     # Multi-tenant support
â”‚   â”‚   â”‚   â”œâ”€â”€ document_processor.py # Document AI processing
â”‚   â”‚   â”‚   â”œâ”€â”€ enhanced_voice_activity_detector.py # Voice detection
â”‚   â”‚   â”‚   â””â”€â”€ continuous_conversation.py # Real-time conversation
â”‚   â”‚   â”œâ”€â”€ models/                    # Data models
â”‚   â”‚   â”‚   â”œâ”€â”€ user.py               # User model
â”‚   â”‚   â”‚   â”œâ”€â”€ tenant.py             # Tenant model
â”‚   â”‚   â”‚   â””â”€â”€ conversation.py       # Conversation model
â”‚   â”‚   â”œâ”€â”€ middleware/                # Middleware
â”‚   â”‚   â”‚   â””â”€â”€ tenant_middleware.py  # Tenant isolation
â”‚   â”‚   â””â”€â”€ supabase_client.py        # Supabase integration
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ init.sql                  # Database initialization
â”‚   â”‚   â””â”€â”€ supabase_migration.sql    # Supabase migration
â”‚   â”œâ”€â”€ requirements.txt              # Python dependencies
â”‚   â”œâ”€â”€ Dockerfile                    # Backend container
â”‚   â””â”€â”€ simple_test.py               # Development server
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ aura-react-frontend/          # React TypeScript app
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ components/           # React components
â”‚   â”‚   â”‚   â”œâ”€â”€ pages/                # Page components
â”‚   â”‚   â”‚   â”œâ”€â”€ contexts/             # React contexts
â”‚   â”‚   â”‚   â””â”€â”€ hooks/                # Custom hooks
â”‚   â”‚   â””â”€â”€ package.json              # Frontend dependencies
â”‚   â”œâ”€â”€ admin/                        # Admin dashboard (HTML/JS)
â”‚   â”œâ”€â”€ widget/                       # Voice widget (HTML/JS)
â”‚   â””â”€â”€ shared/                       # Shared utilities
â”œâ”€â”€ test/                             # Test scripts
â”‚   â”œâ”€â”€ test_api_keys.py             # API key testing
â”‚   â”œâ”€â”€ test_complete_pipeline.py    # Full pipeline testing
â”‚   â”œâ”€â”€ test_continuous_voice.py     # Voice conversation testing
â”‚   â”œâ”€â”€ test_streaming.py            # Streaming functionality testing
â”‚   â”œâ”€â”€ test_voice_pipeline.py       # Voice pipeline testing
â”‚   â””â”€â”€ test_*.py                     # Other test files
â”œâ”€â”€ docs/                             # Documentation
â”‚   â”œâ”€â”€ SYSTEM_ARCHITECTURE.md       # System architecture
â”‚   â”œâ”€â”€ DEVELOPER_GUIDE.md           # Developer documentation
â”‚   â”œâ”€â”€ CONTINUOUS_VOICE_GUIDE.md    # Voice system guide
â”‚   â”œâ”€â”€ IMPLEMENTATION_ROADMAP.md    # Development roadmap
â”‚   â”œâ”€â”€ TROUBLESHOOTING_GUIDE.md     # Troubleshooting
â”‚   â”œâ”€â”€ QUICK_REFERENCE.md           # Quick reference
â”‚   â””â”€â”€ websocket-api.md             # WebSocket API docs
â”œâ”€â”€ deployment/                       # Deployment configs
â”œâ”€â”€ scripts/                          # Utility scripts
â”œâ”€â”€ docker-compose.yml               # Docker configuration
â”œâ”€â”€ SUPABASE_SETUP_GUIDE.md          # Supabase setup guide
â””â”€â”€ README.md                        # This file
```

## ğŸ”§ Configuration

### Environment Variables

Create a `.env` file in the `backend` directory:

```env
# LLM APIs
GROK_API_KEY=xai-your-key-here
OPENAI_API_KEY=sk-your-key-here

# Voice APIs
ELEVENLABS_API_KEY=sk_your-key-here
ELEVENLABS_VOICE_ID=your-voice-id

# Database
DATABASE_URL=postgresql://user:password@localhost/aura_db

# Optional
REDIS_URL=redis://localhost:6379
```

### Frontend Configuration

The React frontend is configured with:
- **Vite** for fast development and building
- **Tailwind CSS** for styling
- **TypeScript** for type safety
- **Supabase** for backend integration

## ğŸ§ª Testing

### Interactive Web Interface
```bash
# Start backend server and open:
http://localhost:8000/test
```

### Frontend Development
```bash
cd frontend/aura-react-frontend
npm run dev          # Start dev server
npm run build        # Build for production
npm run preview      # Preview production build
```

### Run Test Scripts
```bash
cd test
python test_api_keys.py            # Test API key configuration
python test_complete_pipeline.py   # Test full voice pipeline
python test_continuous_voice.py    # Test real-time voice conversation
python test_streaming.py           # Test streaming functionality
python test_voice_pipeline.py      # Test voice pipeline components
python test_router.py              # Test LLM routing
python test_memory.py              # Test memory system
python test_voice.py               # Test voice components
python test_tts.py                 # Test text-to-speech
python test_document.py            # Test document processing
```

### API Testing with cURL
```bash
# Health check
curl http://localhost:8000/health

# Send chat message
curl -X POST http://localhost:8000/chat/message \
  -H "Content-Type: application/json" \
  -d '{"message": "Hello, AURA!"}'

# Generate speech
curl -X POST http://localhost:8000/voice/synthesize \
  -F "text=Hello, this is AURA speaking" \
  --output audio.mp3

# Test continuous voice
curl -X POST http://localhost:8000/continuous-voice/start \
  -H "Content-Type: application/json" \
  -d '{"user_id": "test_user"}'
```

## ğŸ“Š API Endpoints

### Core Endpoints
- `GET /` - System info
- `GET /health` - Health check
- `GET /test` - Interactive test interface

### Chat
- `POST /chat/message` - Send message
- `GET /chat/history/{user_id}` - Get chat history

### Voice
- `POST /voice/synthesize` - Text to speech
- `POST /voice/transcribe` - Speech to text
- `GET /voice/status` - Voice system status

### Continuous Voice (NEW)
- `POST /continuous-voice/start` - Start real-time voice session
- `POST /continuous-voice/process` - Process voice input
- `POST /continuous-voice/stop` - Stop voice session

### Documents (NEW)
- `POST /documents/upload` - Upload and process documents
- `GET /documents/{doc_id}` - Get document information
- `DELETE /documents/{doc_id}` - Delete document

### Admin
- `GET /admin/dashboard` - System statistics
- `POST /admin/upload-knowledge` - Upload knowledge files
- `GET /admin/knowledge` - List knowledge base

### Memory
- `GET /memory/preferences/{user_id}` - Get user preferences
- `PUT /memory/preferences/{user_id}` - Update preferences
- `GET /memory/export/{user_id}` - Export user data
- `DELETE /memory/delete/{user_id}` - Delete user data

## ğŸ¯ Performance Targets

- **Response Time**: < 2 seconds
- **Voice Quality**: MOS > 4.0
- **Uptime**: 99.5%
- **Memory Retrieval**: < 100ms
- **API Success Rate**: > 95%
- **Real-time Voice Processing**: < 100ms latency


## ğŸ› Troubleshooting

### Common Issues

**Submodule Issues (Frontend not loading)**
```bash
# If frontend directory is empty or incomplete:
git submodule update --init --recursive

# Or navigate to frontend and initialize:
cd frontend/aura-react-frontend
git submodule update --init
```

**Voice AI Not Responding (Most Common Issue)**
```bash
# Check if you have API keys configured:
cd backend
python debug_env.py

# If you see "âœ—" for any API key, you need to:
# 1. Copy the example file:
cp env.example .env

# 2. Edit .env and add your API keys:
# GROK_API_KEY=xai-your-actual-key
# OPENAI_API_KEY=sk-your-actual-key  
# ELEVENLABS_API_KEY=sk_your-actual-key

# 3. Restart the backend server
```

**API Key Errors**
```bash
# Check your .env file
cat backend/.env
# Ensure all keys are set correctly
```

**Frontend Dependencies**
```bash
# If npm install fails in frontend:
cd frontend/aura-react-frontend
rm -rf node_modules package-lock.json
npm install
```

**Redis Connection Failed**
```bash
# System will use in-memory fallback
# Or install Redis:
docker-compose up redis
```

**Port Already in Use**
```bash
# Use a different port for backend
uvicorn app.main:app --port 8001

# Use a different port for frontend
cd frontend/aura-react-frontend
npm run dev -- --port 3000
```

### Development Workflow

**For Backend Changes:**
```bash
# Make changes in backend/
git add .
git commit -m "Your backend changes"
git push
```

**For Frontend Changes:**
```bash
# Make changes in frontend/aura-react-frontend/
cd frontend/aura-react-frontend
git add .
git commit -m "Your frontend changes"
git push

# Then update main repo to track new frontend commit
cd ../..
git add frontend/aura-react-frontend
git commit -m "Update frontend submodule"
git push
```

## ğŸ“ License

Proprietary Software License - See [LICENSE](LICENSE) file for details

**âš ï¸ RESTRICTED USE**: This software is proprietary and confidential to Aura Team. Unauthorized use is prohibited.

## ğŸ¤ Contributing

This is proprietary software developed exclusively by Aura Team. External contributions are not accepted.

**For Aura Team Members:**
- Backend changes go in the main repository
- Frontend changes go in the `frontend/aura-react-frontend` submodule
- Always update submodule references when frontend changes are made
- Follow internal development guidelines and code review processes

## ğŸ“š Documentation

Comprehensive documentation is available in the `docs/` folder:

- **[Documentation Index](docs/README.md)** - Navigate all documentation
- **[Developer Guide](docs/DEVELOPER_GUIDE.md)** - Complete development documentation
- **[System Architecture](docs/SYSTEM_ARCHITECTURE.md)** - Technical architecture
- **[Continuous Voice Guide](docs/CONTINUOUS_VOICE_GUIDE.md)** - Voice system guide
- **[Troubleshooting Guide](docs/TROUBLESHOOTING_GUIDE.md)** - Common issues and solutions
- **[Quick Reference](docs/QUICK_REFERENCE.md)** - Essential commands
- **[WebSocket API](docs/websocket-api.md)** - Real-time communication protocol

## ğŸ“§ Support

For issues and questions:
- Check the [Documentation Index](docs/README.md) for guidance
- Review the [Troubleshooting Guide](docs/TROUBLESHOOTING_GUIDE.md) for common issues
- Open an issue on GitHub
- Check the test interface at `/test`
- Review logs for debugging
- Check frontend console for frontend issues

## ğŸš€ Deployment

### Docker Deployment
```bash
# Multi-tenant deployment
docker-compose -f docker-compose.multi-tenant.yml up -d

# Standard deployment
docker-compose up -d
```

---

## ğŸ“„ License

This software is proprietary and confidential to Aura Team. All rights reserved.

**âš ï¸ IMPORTANT**: This software is NOT open source. It is proprietary software owned exclusively by Aura Team. Unauthorized use, copying, distribution, or modification is strictly prohibited and may result in legal action.

For licensing inquiries, contact: [contact@aurateam.com]

---

**Made with â¤ï¸ by Aura Team** - Multi-tenant Voice AI Platform
